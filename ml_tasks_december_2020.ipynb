{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Tasks\n",
    "\n",
    "* The aim of these tasks is to demonstrate a justifiable approach to common ML tasks.\n",
    "* The aim is **not** particularly about code quality. \n",
    "* Only spend a small amount of time summarising work in markdown cells (<20% total time), focus on the data manipulation and model build."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regression: Data preparation and model build\n",
    "\n",
    "## Goals\n",
    "\n",
    "* Explore and plot data\n",
    "    * establish distributions of variables\n",
    "    * find any problems in the data to fix\n",
    "\n",
    "Write a simple model-building pipeline including the three tasks below:\n",
    "\n",
    "* Clean data\n",
    "    * fix any problems with the data that are necessary to fix before building a model\n",
    "* Normalise data\n",
    "    * normalise the variables for use in a linear regression \n",
    "* Fit and evaluate model\n",
    "    * estimate the generalisation error of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    AGE  SEX   BMI     BP     S1     S2    S3   S4          S5    S6\n",
      "0  59.0  2.0        101.0  157.0   93.2  38.0  NaN  110.383198  87.0\n",
      "1  48.0  1.0         87.0  183.0  103.2  70.0  3.0   43.731989   NaN\n",
      "2  72.0  NaN  30.5   93.0  156.0   93.6  41.0  4.0   61.926388  85.0\n",
      "3  24.0  1.0  25.3   84.0  198.0  131.4  40.0  5.0  154.266706  89.0\n",
      "4  50.0  1.0  23.0  101.0  192.0  125.4  52.0  4.0  154.005616  80.0\n",
      "\n",
      "\n",
      "0    151.0\n",
      "1     75.0\n",
      "2    141.0\n",
      "3    206.0\n",
      "4    135.0\n",
      "Name: Y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "X, y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "\n",
    "print(X.head())\n",
    "print(\"\\n\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. General ML\n",
    "To be discussed verbally.\n",
    "### 2.1\n",
    "In a regression problem with feature vectors $\\mathbf{x_1}, ..., \\mathbf{x_n} \\in {\\rm I\\!R^d}$ and targets $y_1, ..., y_n \\in {\\rm I\\!R}$, how would you adjust the following loss function on parameters $\\mathbf{b} \\in {\\rm I\\!R^d}$ to achieve the sparsest solution?\n",
    "$$\\mathcal{L}(\\mathbf{b}) = \\sum_{i=1}^n (y_i - \\mathbf{x_ib})^2 + \\lambda\\sum_{j=1}^d |b_j|^q$$\n",
    "\n",
    "### 2.2\n",
    "What methods and models might you use on a supervised learning problem with a high cardinality (>10000) categorical feature, several lower cardinality (<20) categoricals, and 2-3 real valued features? Discuss pros and cons of different models and methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
