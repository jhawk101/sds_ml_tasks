{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Tasks\n",
    "The aim of these tasks is to demonstrate a justifiable approach to common ML tasks. The aim is **not** particularly about code quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simple Model Selection\n",
    "## Goals\n",
    "- We want to compare:\n",
    "    - Missing data strategy: mean vs median\n",
    "    - Model: Lasso Vs Ridge\n",
    "- We want to find the model that will have the lowest error in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = sklearn.datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "# Fill 5% of data with NaN's\n",
    "data = data * np.random.choice([1, np.nan], size=data.shape, p=[0.95, 0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classifier Evaluation\n",
    "We have a binary classification task. The ground truth labels are loaded along with predictions from one of our models.\n",
    "\n",
    "Quantify and comment on the quality and usefulness of these predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.load(\"classifier_predictions.npy\")\n",
    "targets = np.load(\"classifier_targets.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. General ML\n",
    "To be discussed verbally.\n",
    "### 3.1\n",
    "In a regression problem with feature vectors $\\mathbf{x_1}, ..., \\mathbf{x_n} \\in {\\rm I\\!R^d}$ and targets $y_1, ..., y_n \\in {\\rm I\\!R}$ how would you adjust the following loss function on parameters $\\mathbf{b} \\in {\\rm I\\!R^d}$ to achieve the sparsest solution?\n",
    "$$\\mathcal{L}(\\mathbf{b}) = \\sum_{i=1}^n (y_i - \\mathbf{x_ib})^2 + \\sum_{j=1}^d |b_j|^q$$\n",
    "\n",
    "### 3.2\n",
    "What methods and models might you use on a supervised learning problem with a high cardinality (>10000) categorical feature, several lower cardinality (<20) categoricals, and 2-3 real valued features? Discuss pros and cons of different models and methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Selection Continued\n",
    "Build on your work from part 1 to add feature selection and parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = sklearn.datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "# Fill 5% of data with NaN's\n",
    "data = data * np.random.choice([1, np.nan], size=data.shape, p=[0.95, 0.05])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
